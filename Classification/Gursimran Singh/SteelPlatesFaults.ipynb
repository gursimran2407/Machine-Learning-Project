{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "class entryPoint():\n",
    "\n",
    "  def printaccuracy(self,y_test,predict,model):\n",
    "    print(model,\" report\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\" Confusion Matrix \" ,confusion_matrix(y_test,predict))\n",
    "    print(classification_report(y_test,predict))\n",
    "    print(\" \")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\" \")\n",
    "    \n",
    "  def normalizedata(self,X):\n",
    "    SS = StandardScaler()\n",
    "    X = SS.fit_transform(X)\n",
    "    print(\"Normalization done\")\n",
    "    return X\n",
    "\t\n",
    "\t\n",
    "  def removeoutliers(self,data,inplace=False):\n",
    "    prev_rows = len(data)\n",
    "    data_copy = data.copy()\n",
    "    z_score = np.abs(stats.zscore(data_copy))\n",
    "    data_copy = data_copy[(z_score < 3).all(axis=1)]\n",
    "    if inplace:\n",
    "      data=data_copy\n",
    "    print(\"Before removing outliers , rows - \", prev_rows)\n",
    "    print(\"After removing outliers , rows -\", len(data_copy))\n",
    "    print(\"Number of records deleted - \", (prev_rows - len(data_copy)))\n",
    "    return data_copy\n",
    "\n",
    "  def train_split(self,X,y,test_size=0.2,random_state=0):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "  def knn(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Knn\")\n",
    "    knn_error = []\n",
    "    for i in range(2,10):\n",
    "      knn = KNeighborsClassifier(n_neighbors=i)\n",
    "      knn.fit(X_train,y_train)\n",
    "      knn_predict= knn.predict(X_test)\n",
    "      print(type(knn_predict))\n",
    "      print(type(y_test))\n",
    "      knn_error.append(np.mean(y_test!=knn_predict))\n",
    "    plt.plot(range(2,50),knn_error)\n",
    "    plt.xlabel(\"K value\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\t\n",
    "  def knn_grid_search(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Knn Grid Search Starting...\")\n",
    "    neighbors={'n_neighbors':np.array(range(2,10))}\n",
    "    knn_grid=sklearn.model_selection.GridSearchCV(KNeighborsClassifier(),neighbors,verbose=False,refit=True,cv=3)\n",
    "    knn_grid.fit(X_train,y_train.values.ravel())\n",
    "    knn_predict = knn_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,knn_predict,\"KNN\")\n",
    "    print(\"Best Hyperparameters \" + str(knn_grid.best_params_) + \" Best Score: \" + str(knn_grid.best_score_))\n",
    "    flScore = f1_score(y_test,knn_predict)\n",
    "    return flScore\n",
    "    \n",
    "  def logisticRegression(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Logistic Regression classification Starting...\")\n",
    "    Co_reg= np.logspace(-4, 4, 20)\n",
    "    penalty_reg = ['l1','l2']\n",
    "    max_iteration = [10,100,1000]\n",
    "    score = []\n",
    "    for pen in penalty_reg:\n",
    "      for i in Co_reg:\n",
    "        for it in max_iteration:\n",
    "          clf = LogisticRegression(random_state=0, solver='liblinear', penalty=pen , C=i, max_iter=it).fit(X_train, y_train.values.ravel())\n",
    "          score.append(clf.score(X_test, y_test.values.ravel()))\n",
    "    \n",
    "    print(\"Best Score : \" + str(max(score)))\n",
    "        \n",
    "  def svm_model(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"SVM Classification Starting...\")\n",
    "    svm = SVC(kernel='rbf',random_state=0)\t\n",
    "    params = inp_params\n",
    "    svm_grid = GridSearchCV(svm, params, verbose=1, cv=3,return_train_score=True)\n",
    "    svm_grid.fit(X_train,y_train.ravel())\n",
    "    svm_predict = svm_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,svm_predict,\"SVM\")\n",
    "    print(\"Best Hyperparameters \" + str(svm_grid.best_params_) + \" Best Score: \" + str(svm_grid.best_score_))\n",
    "    return f1_score(y_test,svm_predict)\n",
    "\t\t\n",
    "  def decisionTreeClassifier(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"Decisiontree Classifier Starting...\")\n",
    "    params = inp_params\n",
    "    decisionTree_grid = GridSearchCV(DecisionTreeClassifier(), params, verbose=1, cv=3,return_train_score=True)\n",
    "    decisionTree_grid.fit(X_train,y_train.ravel())\n",
    "    decisionTree_predict = decisionTree_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,decisionTree_predict,\"DecisionTree\")\n",
    "    print(\"Best Hyperparameters \" + str(decisionTree_predict.best_params_) + \" Best Score: \" + str(decisionTree_predict.best_score_))\n",
    "    return f1_score(y_test,decisionTree_predict)\n",
    "    \n",
    "  def randomForest(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"randomForest Classifier Starting...\")\n",
    "    rf = RandomForestClassifier()\n",
    "    params = inp_params\n",
    "    rf_grid = GridSearchCV(rf, params, verbose=1, cv=3)\n",
    "    rf_grid.fit(X_train,y_train.ravel())\n",
    "    rf_predict = rf_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,rf_predict,\"RandomForest\")\n",
    "    print(\"Best Hyperparameters \" + str(rf_grid.best_params_) + \" Best Score: \" + str(rf_grid.best_score_))\n",
    "    return f1_score(y_test,rf_predict)\n",
    "    \n",
    "  def adaBoost(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"AdaBoost Classifier Starting...\")\n",
    "    ab = AdaBoostClassifier()\n",
    "    params = inp_params\n",
    "    ab_grid = GridSearchCV(ab, params, verbose=1, cv=3)\n",
    "    ab_grid.fit(X_train,y_train)\n",
    "    ab_predict = ab_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,ab_predict,\"AdaBoost\")\n",
    "    print(\"Best Hyperparameters \" + str(ab_grid.best_params_) + \" Best Score: \" + str(ab_grid.best_score_))\n",
    "    return f1_score(y_test,ab_predict)\n",
    "    \n",
    "  def gaussianNaiveBaive(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"GaussianNaiveBaive Classifier Starting... \")\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    gnb_predict = gnb.predict(X_test)\n",
    "    self.printaccuracy(y_test,gnb_predict,\"Naive Bayes\")\n",
    "    return f1_score(y_test,gnb_predict)\n",
    "\t\t\n",
    "  def neuralNetworks(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"NeuralNetworks Classifier Starting...\")\n",
    "    nn = MLPClassifier(solver='sgd',random_state=0)\n",
    "    params = inp_params\n",
    "    nn_grid = GridSearchCV(nn, params, cv=3)\n",
    "    nn_grid.fit(X_train,y_train)\n",
    "    nn_predict = nn_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,nn_predict,\"Neural Networks\")\n",
    "    print(\"Best Hyperparameters \" + str(nn_grid.best_params_) + \" Best Score: \" + str(nn_grid.best_score_))\n",
    "    return f1_score(y_test,nn_predict)\n",
    "\n",
    "  def train_models(self,X_train,y_train,X_test,y_test,):\n",
    "    f1scores = []\n",
    "    #f1scores.append(self.knn(X_train,y_train,X_test,y_test))\n",
    "    f1scores.append(self.knn_grid_search(X_train,y_train,X_test,y_test))\n",
    "    return f1scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  Other_Faults\n",
       "600       0          0         1       0          0      0             0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_list= ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas', 'Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "\n",
    "data = pd.read_csv(\"../Datasets/SteelPlatesFaults/Faults.NNA\",delimiter = '\\s+',names=long_list)\n",
    "\n",
    "X = pd.DataFrame(data,columns=['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas'])\n",
    "\n",
    "y = data.iloc[:,27:34]\n",
    "y[600:601]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#need to make 7 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 7 columns into one y 'class' column\n",
    "def fun1(x):\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 1:\n",
    "            return i\n",
    "y1= []        \n",
    "for j in range(len(y)):        \n",
    "    y1.append((fun1(y.iloc[j])))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = pd.DataFrame(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2.columns=['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        0\n",
       "13        0\n",
       "14        0\n",
       "15        0\n",
       "16        0\n",
       "17        0\n",
       "18        0\n",
       "19        0\n",
       "20        0\n",
       "21        0\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        0\n",
       "...     ...\n",
       "1911      6\n",
       "1912      6\n",
       "1913      6\n",
       "1914      6\n",
       "1915      6\n",
       "1916      6\n",
       "1917      6\n",
       "1918      6\n",
       "1919      6\n",
       "1920      6\n",
       "1921      6\n",
       "1922      6\n",
       "1923      6\n",
       "1924      6\n",
       "1925      6\n",
       "1926      6\n",
       "1927      6\n",
       "1928      6\n",
       "1929      6\n",
       "1930      6\n",
       "1931      6\n",
       "1932      6\n",
       "1933      6\n",
       "1934      6\n",
       "1935      6\n",
       "1936      6\n",
       "1937      6\n",
       "1938      6\n",
       "1939      6\n",
       "1940      6\n",
       "\n",
       "[1941 rows x 1 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y =y2\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization done\n",
      "(1358, 27)\n",
      "(583, 27)\n",
      "(1358, 1)\n",
      "(583, 1)\n",
      "Knn Grid Search Starting...\n",
      "KNN  report\n",
      "-------------------------------------\n",
      " \n",
      " Confusion Matrix  [[ 20   2   0   0   0  11  11]\n",
      " [  0  50   0   0   0   2   3]\n",
      " [  0   1 112   0   0   1   3]\n",
      " [  0   0   0  26   0   0   0]\n",
      " [  0   0   0   0  18   0   0]\n",
      " [  6   5   0   0   0  76  24]\n",
      " [ 13   6   4   2   0  48 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.45      0.48        44\n",
      "           1       0.78      0.91      0.84        55\n",
      "           2       0.97      0.96      0.96       117\n",
      "           3       0.93      1.00      0.96        26\n",
      "           4       1.00      1.00      1.00        18\n",
      "           5       0.55      0.68      0.61       111\n",
      "           6       0.77      0.66      0.71       212\n",
      "\n",
      "    accuracy                           0.76       583\n",
      "   macro avg       0.79      0.81      0.80       583\n",
      "weighted avg       0.76      0.76      0.76       583\n",
      "\n",
      " \n",
      "-------------------------------------\n",
      " \n",
      "Best Hyperparameters {'n_neighbors': 5} Best Score: 0.6995581737849779\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-03b019274df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mflscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentrypoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-8b2a096d2988>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mf1scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m#f1scores.append(self.knn(X_train,y_train,X_test,y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-8b2a096d2988>\u001b[0m in \u001b[0;36mknn_grid_search\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintaccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Hyperparameters \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Best Score: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mflScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mflScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[1;32m   1058\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m                        sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1415\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1253\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "entrypoint = entryPoint()\n",
    "X = entrypoint.normalizedata(X)\n",
    "X_train,X_test,y_train,y_test = entrypoint.train_split(X,y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "flscores = entrypoint.train_models(X_train,y_train,X_test,y_test)\n",
    "print(flscores)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
