{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class entryPoint():\n",
    "\n",
    "  def printaccuracy(self,y_test,predict,model):\n",
    "    print(model,\" report\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\" \")\n",
    "    print(\" Confusion Matrix \" ,confusion_matrix(y_test,predict))\n",
    "    print(classification_report(y_test,predict))\n",
    "    print(\" \")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\" \")\n",
    "    \n",
    "  def normalizedata(self,X):\n",
    "    SS = StandardScaler()\n",
    "    X = SS.fit_transform(X)\n",
    "    print(\"Normalization done\")\n",
    "    return X\n",
    "\t\n",
    "\t\n",
    "  def removeoutliers(self,data,inplace=False):\n",
    "    prev_rows = len(data)\n",
    "    data_copy = data.copy()\n",
    "    z_score = np.abs(stats.zscore(data_copy))\n",
    "    data_copy = data_copy[(z_score < 3).all(axis=1)]\n",
    "    if inplace:\n",
    "      data=data_copy\n",
    "    print(\"Before removing outliers , rows - \", prev_rows)\n",
    "    print(\"After removing outliers , rows -\", len(data_copy))\n",
    "    print(\"Number of records deleted - \", (prev_rows - len(data_copy)))\n",
    "    return data_copy\n",
    "\n",
    "  def train_split(self,X,y,test_size=0.2,random_state=0):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "  def knn(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Knn\")\n",
    "    knn_error = []\n",
    "    for i in range(2,10):\n",
    "      knn = KNeighborsClassifier(n_neighbors=i)\n",
    "      knn.fit(X_train,y_train)\n",
    "      knn_predict= knn.predict(X_test)\n",
    "      print(type(knn_predict))\n",
    "      print(type(y_test))\n",
    "      knn_error.append(np.mean(y_test!=knn_predict))\n",
    "    plt.plot(range(2,50),knn_error)\n",
    "    plt.xlabel(\"K value\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\t\n",
    "  def knn_grid_search(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Knn Grid Search Starting...\")\n",
    "    neighbors={'n_neighbors':np.array(range(2,10))}\n",
    "    knn_grid=GridSearchCV(KNeighborsClassifier(),neighbors,verbose=False,refit=True,cv=3)\n",
    "    knn_grid.fit(X_train,y_train.values.ravel())\n",
    "    knn_predict = knn_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,knn_predict,\"KNN\")\n",
    "    print(\"Best Hyperparameters \" + str(knn_grid.best_params_) + \" Best Score: \" + str(knn_grid.best_score_))\n",
    "    flScore = f1_score(y_test,knn_predict)\n",
    "    return flScore\n",
    "    \n",
    "  def logisticRegression(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"Logistic Regression classification Starting...\")\n",
    "    Co_reg= np.logspace(-4, 4, 20)\n",
    "    penalty_reg = ['l1','l2']\n",
    "    max_iteration = [10,100,1000]\n",
    "    score = []\n",
    "    for pen in penalty_reg:\n",
    "      for i in Co_reg:\n",
    "        for it in max_iteration:\n",
    "          clf = LogisticRegression(random_state=0, solver='liblinear', penalty=pen , C=i, max_iter=it).fit(X_train, y_train.values.ravel())\n",
    "          score.append(clf.score(X_test, y_test.values.ravel()))\n",
    "    \n",
    "    print(\"Best Score : \" + str(max(score)))\n",
    "        \n",
    "  def svm_model(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"SVM Classification Starting...\")\n",
    "    svm = SVC(kernel='rbf',random_state=0)\t\n",
    "    params = inp_params\n",
    "    svm_grid = GridSearchCV(svm, params, verbose=1, cv=3,return_train_score=True)\n",
    "    svm_grid.fit(X_train,y_train.ravel())\n",
    "    svm_predict = svm_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,svm_predict,\"SVM\")\n",
    "    print(\"Best Hyperparameters \" + str(svm_grid.best_params_) + \" Best Score: \" + str(svm_grid.best_score_))\n",
    "    return f1_score(y_test,svm_predict)\n",
    "\t\t\n",
    "  def decisionTreeClassifier(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"Decisiontree Classifier Starting...\")\n",
    "    params = inp_params\n",
    "    decisionTree_grid = GridSearchCV(DecisionTreeClassifier(), params, verbose=1, cv=3,return_train_score=True)\n",
    "    decisionTree_grid.fit(X_train,y_train.ravel())\n",
    "    decisionTree_predict = decisionTree_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,decisionTree_predict,\"DecisionTree\")\n",
    "    print(\"Best Hyperparameters \" + str(decisionTree_predict.best_params_) + \" Best Score: \" + str(decisionTree_predict.best_score_))\n",
    "    return f1_score(y_test,decisionTree_predict)\n",
    "    \n",
    "  def randomForest(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"randomForest Classifier Starting...\")\n",
    "    rf = RandomForestClassifier()\n",
    "    params = inp_params\n",
    "    rf_grid = GridSearchCV(rf, params, verbose=1, cv=3)\n",
    "    rf_grid.fit(X_train,y_train.ravel())\n",
    "    rf_predict = rf_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,rf_predict,\"RandomForest\")\n",
    "    print(\"Best Hyperparameters \" + str(rf_grid.best_params_) + \" Best Score: \" + str(rf_grid.best_score_))\n",
    "    return f1_score(y_test,rf_predict)\n",
    "    \n",
    "  def adaBoost(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"AdaBoost Classifier Starting...\")\n",
    "    ab = AdaBoostClassifier()\n",
    "    params = inp_params\n",
    "    ab_grid = GridSearchCV(ab, params, verbose=1, cv=3)\n",
    "    ab_grid.fit(X_train,y_train)\n",
    "    ab_predict = ab_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,ab_predict,\"AdaBoost\")\n",
    "    print(\"Best Hyperparameters \" + str(ab_grid.best_params_) + \" Best Score: \" + str(ab_grid.best_score_))\n",
    "    return f1_score(y_test,ab_predict)\n",
    "    \n",
    "  def gaussianNaiveBaive(self,X_train,y_train,X_test,y_test):\n",
    "    print(\"GaussianNaiveBaive Classifier Starting... \")\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    gnb_predict = gnb.predict(X_test)\n",
    "    self.printaccuracy(y_test,gnb_predict,\"Naive Bayes\")\n",
    "    return f1_score(y_test,gnb_predict)\n",
    "\t\t\n",
    "  def neuralNetworks(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "    print(\"NeuralNetworks Classifier Starting...\")\n",
    "    nn = MLPClassifier(solver='sgd',random_state=0)\n",
    "    params = inp_params\n",
    "    nn_grid = GridSearchCV(nn, params, cv=3)\n",
    "    nn_grid.fit(X_train,y_train)\n",
    "    nn_predict = nn_grid.predict(X_test)\n",
    "    self.printaccuracy(y_test,nn_predict,\"Neural Networks\")\n",
    "    print(\"Best Hyperparameters \" + str(nn_grid.best_params_) + \" Best Score: \" + str(nn_grid.best_score_))\n",
    "    return f1_score(y_test,nn_predict)\n",
    "\n",
    "  def train_models(self,X_train,y_train,X_test,y_test,):\n",
    "    f1scores = []\n",
    "    #f1scores.append(self.knn(X_train,y_train,X_test,y_test))\n",
    "    f1scores.append(self.knn_grid_search(X_train,y_train,X_test,y_test))\n",
    "    return f1scores\n",
    "\n",
    "  def creditCardDataset(self):\n",
    "    #For credit card Defaulters \n",
    "    df = pd.read_csv(\"credit.csv\")\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    df = df.iloc[1:]\n",
    "    df = df.astype(float)\n",
    "    df = self.removeoutliers(df,inplace=True)\n",
    "    X = df.iloc[:,:23]\n",
    "    y = df.iloc[:,23:24]\n",
    "    X = entrypoint.normalizedata(X)\n",
    "    X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    flscores = self.train_models(X_train,y_train,X_test,y_test)\n",
    "    print(flscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seismic</th>\n",
       "      <th>seismoacoustic</th>\n",
       "      <th>shift</th>\n",
       "      <th>genergy</th>\n",
       "      <th>gpuls</th>\n",
       "      <th>gdenergy</th>\n",
       "      <th>gdpuls</th>\n",
       "      <th>ghazard</th>\n",
       "      <th>nbumps</th>\n",
       "      <th>nbumps2</th>\n",
       "      <th>nbumps3</th>\n",
       "      <th>nbumps4</th>\n",
       "      <th>nbumps5</th>\n",
       "      <th>nbumps6</th>\n",
       "      <th>nbumps7</th>\n",
       "      <th>nbumps89</th>\n",
       "      <th>energy</th>\n",
       "      <th>maxenergy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>15180</td>\n",
       "      <td>48</td>\n",
       "      <td>-72</td>\n",
       "      <td>-72</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>14720</td>\n",
       "      <td>33</td>\n",
       "      <td>-70</td>\n",
       "      <td>-79</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>8050</td>\n",
       "      <td>30</td>\n",
       "      <td>-81</td>\n",
       "      <td>-78</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>28820</td>\n",
       "      <td>171</td>\n",
       "      <td>-23</td>\n",
       "      <td>40</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>12640</td>\n",
       "      <td>57</td>\n",
       "      <td>-63</td>\n",
       "      <td>-52</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seismic seismoacoustic shift  genergy  gpuls  gdenergy  gdpuls ghazard  \\\n",
       "0       a              a     N    15180     48       -72     -72       a   \n",
       "1       a              a     N    14720     33       -70     -79       a   \n",
       "2       a              a     N     8050     30       -81     -78       a   \n",
       "3       a              a     N    28820    171       -23      40       a   \n",
       "4       a              a     N    12640     57       -63     -52       a   \n",
       "\n",
       "   nbumps  nbumps2  nbumps3  nbumps4  nbumps5  nbumps6  nbumps7  nbumps89  \\\n",
       "0       0        0        0        0        0        0        0         0   \n",
       "1       1        0        1        0        0        0        0         0   \n",
       "2       0        0        0        0        0        0        0         0   \n",
       "3       1        0        1        0        0        0        0         0   \n",
       "4       0        0        0        0        0        0        0         0   \n",
       "\n",
       "   energy  maxenergy  class  \n",
       "0       0          0      0  \n",
       "1    2000       2000      0  \n",
       "2       0          0      0  \n",
       "3    3000       3000      0  \n",
       "4       0          0      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(\"../Datasets/SeismicBumps/seismic-bumps.arff\",delimiter = ',',names=[\"seismic\",\"seismoacoustic\",\"shift\",\"genergy\",\"gpuls\",\"gdenergy\",\"gdpuls\",\"ghazard\",\"nbumps\",\"nbumps2\",\"nbumps3\",\"nbumps4\",\"nbumps5\",\"nbumps6\",\"nbumps7\",\"nbumps89\",\"energy\",\"maxenergy\",\"class\"])\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data,columns=[\"seismic\",\"seismoacoustic\",\"shift\",\"genergy\",\"gpuls\",\"gdenergy\",\"gdpuls\",\"ghazard\",\"nbumps\",\"nbumps2\",\"nbumps3\",\"nbumps4\",\"nbumps5\",\"nbumps6\",\"nbumps7\",\"nbumps89\",\"energy\",\"maxenergy\"])\n",
    "cat = [\"seismic\",\"seismoacoustic\",\"shift\",\"ghazard\"]\n",
    "\n",
    "for i in cat:\n",
    "    X[i] = pd.Categorical(X[i]).codes\n",
    "    \n",
    "y = data.iloc[:,18:29]\n",
    "y['class'] = pd.Categorical(y['class']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization done\n",
      "(1808, 18)\n",
      "(776, 18)\n",
      "(1808, 1)\n",
      "(776, 1)\n",
      "Knn Grid Search Starting...\n",
      "KNN  report\n",
      "-------------------------------------\n",
      " \n",
      " Confusion Matrix  [[717   3]\n",
      " [ 55   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       720\n",
      "           1       0.25      0.02      0.03        56\n",
      "\n",
      "    accuracy                           0.93       776\n",
      "   macro avg       0.59      0.51      0.50       776\n",
      "weighted avg       0.88      0.93      0.89       776\n",
      "\n",
      " \n",
      "-------------------------------------\n",
      " \n",
      "Best Hyperparameters {'n_neighbors': 4} Best Score: 0.9347345132743363\n",
      "[0.03333333333333333]\n"
     ]
    }
   ],
   "source": [
    "entrypoint = entryPoint()\n",
    "X = entrypoint.normalizedata(X)\n",
    "X_train,X_test,y_train,y_test = entrypoint.train_split(X,y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "flscores = entrypoint.train_models(X_train,y_train,X_test,y_test)\n",
    "print(flscores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
