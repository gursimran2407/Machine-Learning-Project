{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M672TMuWxHmV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class entryPoint():\n",
    "\n",
    "    def printaccuracy(self,y_test,predict,model):\n",
    "        print(model,\" report\")\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\" \")\n",
    "        print(\" Confusion Matrix \" ,confusion_matrix(y_test,predict))\n",
    "        print(classification_report(y_test,predict))\n",
    "        print(\" \")\n",
    "        print(\"-------------------------------------\")\n",
    "        print(\" \")\n",
    "    \n",
    "    def normalizedata(self,X):\n",
    "        SS = StandardScaler()\n",
    "        X = SS.fit_transform(X)\n",
    "        print(\"Normalization done\")\n",
    "        return X\n",
    "\n",
    "    def removeoutliers(self,data,inplace=False):\n",
    "        prev_rows = len(data)\n",
    "        data_copy = data.copy()\n",
    "        z_score = np.abs(stats.zscore(data_copy))\n",
    "        data_copy = data_copy[(z_score < 3).all(axis=1)]\n",
    "        if inplace:\n",
    "          data=data_copy\n",
    "        print(\"Before removing outliers , rows - \", prev_rows)\n",
    "        print(\"After removing outliers , rows -\", len(data_copy))\n",
    "        print(\"Number of records deleted - \", (prev_rows - len(data_copy)))\n",
    "        return data_copy\n",
    "\n",
    "    def train_split(self,X,y,test_size=0.2,random_state=0):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "        return X_train,X_test,y_train,y_test\n",
    "\n",
    "    def knn(self,X_train,y_train,X_test,y_test):\n",
    "        print(\"Knn\")\n",
    "        knn_error = []\n",
    "        for i in range(2,10):\n",
    "          knn = KNeighborsClassifier(n_neighbors=i)\n",
    "          knn.fit(X_train,y_train)\n",
    "          knn_predict= knn.predict(X_test)\n",
    "          print(type(knn_predict))\n",
    "          print(type(y_test))\n",
    "          knn_error.append(np.mean(y_test!=knn_predict))\n",
    "        plt.plot(range(2,50),knn_error)\n",
    "        plt.xlabel(\"K value\")\n",
    "        plt.ylabel(\"Error\")\n",
    "    \n",
    "    def knn_grid_search(self,X_train,y_train,X_test,y_test):\n",
    "        print(\"Knn Grid Search Starting...\")\n",
    "        neighbors={'n_neighbors':np.array(range(2,10))}\n",
    "        knn_grid=GridSearchCV(KNeighborsClassifier(),neighbors,verbose=False,refit=True,cv=3)\n",
    "        knn_grid.fit(X_train,y_train.values.ravel())\n",
    "        knn_predict = knn_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,knn_predict,\"KNN\")\n",
    "        print(\"Best Hyperparameters \" + str(knn_grid.best_params_) + \" Best Score: \" + str(knn_grid.best_score_))\n",
    "        flScore = f1_score(y_test,knn_predict)\n",
    "        return flScore\n",
    "    \n",
    "    def logisticRegression(self,X_train,y_train,X_test,y_test):\n",
    "        print(\"Logistic Regression classification Starting...\")\n",
    "        Co_reg= np.logspace(-4, 4, 20)\n",
    "        penalty_reg = ['l1','l2']\n",
    "        max_iteration = [10,100,1000]\n",
    "        score = []\n",
    "        for pen in penalty_reg:\n",
    "            for i in Co_reg:\n",
    "                for it in max_iteration:\n",
    "                    clf = LogisticRegression(random_state=0, solver='liblinear', penalty=pen , C=i, max_iter=it).fit(X_train, y_train.values.ravel())\n",
    "                    score.append(clf.score(X_test, y_test.values.ravel()))\n",
    "\n",
    "        print(\"Best Score : \" + str(max(score)))\n",
    "        \n",
    "    def svm_model(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "        print(\"SVM Classification Starting...\")\n",
    "        svm = SVC(kernel='rbf',random_state=0)\t\n",
    "        params = inp_params\n",
    "        svm_grid = GridSearchCV(svm, params, verbose=1, cv=3,return_train_score=True)\n",
    "        svm_grid.fit(X_train,y_train.ravel())\n",
    "        svm_predict = svm_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,svm_predict,\"SVM\")\n",
    "        print(\"Best Hyperparameters \" + str(svm_grid.best_params_) + \" Best Score: \" + str(svm_grid.best_score_))\n",
    "        return f1_score(y_test,svm_predict)\n",
    "\n",
    "    def decisionTreeClassifier(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "        print(\"Decisiontree Classifier Starting...\")\n",
    "        params = inp_params\n",
    "        decisionTree_grid = GridSearchCV(DecisionTreeClassifier(), params, verbose=1, cv=3,return_train_score=True)\n",
    "        decisionTree_grid.fit(X_train,y_train.ravel())\n",
    "        decisionTree_predict = decisionTree_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,decisionTree_predict,\"DecisionTree\")\n",
    "        print(\"Best Hyperparameters \" + str(decisionTree_predict.best_params_) + \" Best Score: \" + str(decisionTree_predict.best_score_))\n",
    "        return f1_score(y_test,decisionTree_predict)\n",
    "    \n",
    "    def randomForest(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "        print(\"randomForest Classifier Starting...\")\n",
    "        rf = RandomForestClassifier()\n",
    "        params = inp_params\n",
    "        rf_grid = GridSearchCV(rf, params, verbose=1, cv=3)\n",
    "        rf_grid.fit(X_train,y_train.ravel())\n",
    "        rf_predict = rf_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,rf_predict,\"RandomForest\")\n",
    "        print(\"Best Hyperparameters \" + str(rf_grid.best_params_) + \" Best Score: \" + str(rf_grid.best_score_))\n",
    "        return f1_score(y_test,rf_predict)\n",
    "\n",
    "    def adaBoost(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "        print(\"AdaBoost Classifier Starting...\")\n",
    "        ab = AdaBoostClassifier()\n",
    "        params = inp_params\n",
    "        ab_grid = GridSearchCV(ab, params, verbose=1, cv=3)\n",
    "        ab_grid.fit(X_train,y_train)\n",
    "        ab_predict = ab_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,ab_predict,\"AdaBoost\")\n",
    "        print(\"Best Hyperparameters \" + str(ab_grid.best_params_) + \" Best Score: \" + str(ab_grid.best_score_))\n",
    "        return f1_score(y_test,ab_predict)\n",
    "    \n",
    "    def gaussianNaiveBaise(self,X_train,y_train,X_test,y_test):\n",
    "        print(\"GaussianNaiveBaive Classifier Starting... \")\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train,y_train)\n",
    "        gnb_predict = gnb.predict(X_test)\n",
    "        self.printaccuracy(y_test,gnb_predict,\"Naive Bayes\")\n",
    "        return f1_score(y_test,gnb_predict)\n",
    "\n",
    "    def neuralNetworks(self,X_train,y_train,X_test,y_test,inp_params):\n",
    "        print(\"NeuralNetworks Classifier Starting...\")\n",
    "        nn = MLPClassifier(solver='sgd',random_state=0)\n",
    "        params = inp_params\n",
    "        nn_grid = GridSearchCV(nn, params, cv=3)\n",
    "        nn_grid.fit(X_train,y_train)\n",
    "        nn_predict = nn_grid.predict(X_test)\n",
    "        self.printaccuracy(y_test,nn_predict,\"Neural Networks\")\n",
    "        print(\"Best Hyperparameters \" + str(nn_grid.best_params_) + \" Best Score: \" + str(nn_grid.best_score_))\n",
    "        return f1_score(y_test,nn_predict)\n",
    "\n",
    "    def train_models(self,X_train,y_train,X_test,y_test,):\n",
    "        f1scores = []\n",
    "        f1scores.append(1)\n",
    "        f1scores.append(self.knn_grid_search(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.logisticRegression(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.randomForest(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.decisionTreeClassifier(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.adaBoost(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.gaussianNaiveBaise(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.neuralNetworks(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.neuralNetworks(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.randomForest(X_train,y_train,X_test,y_test))\n",
    "        f1scores.append(self.svm_model(X_train,y_train,X_test,y_test))     \n",
    "        return f1scores\n",
    "\n",
    "    def creditCardDataset(self):\n",
    "        #For credit card Defaulters \n",
    "        df = pd.read_csv(\"../Datasets/Credit_card/credit.csv\")\n",
    "        df.drop(df.columns[0], axis=1, inplace=True)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "        df = df.iloc[1:]\n",
    "        df = df.astype(float)\n",
    "        df = self.removeoutliers(df,inplace=True)\n",
    "        X = df.iloc[:,:23]\n",
    "        y = df.iloc[:,23:24]\n",
    "        X = self.normalizedata(X)\n",
    "        X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        flscores = self.train_models(X_train,y_train,X_test,y_test)\n",
    "        print(flscores)\n",
    "\n",
    "\n",
    "    def thoratic(self):\n",
    "        data = pd.read_csv(\"../Datasets/9.ThoraticSurgeryData/ThoraricSurgery.arff\",delimiter = ',',names=[\"DGN\", \"PRE4\", \"PRE5\", \"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE14\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\",\"AGE\",\"Risk1Y\"])\n",
    "        data.head()\n",
    "        #Preprocessing\n",
    "        X = pd.DataFrame(data,columns=[\"DGN\", \"PRE4\", \"PRE5\", \"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE14\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\",\"AGE\"])\n",
    "        cat = [\"DGN\",\"PRE6\",\"PRE7\",\"PRE8\",\"PRE9\",\"PRE10\",\"PRE11\",\"PRE14\",\"PRE17\",\"PRE19\",\"PRE25\",\"PRE30\",\"PRE32\"]\n",
    "        for i in cat:\n",
    "            X[i] = pd.Categorical(X[i]).codes\n",
    "        y = data.iloc[:,16:17]\n",
    "        y['Risk1Y'] = pd.Categorical(y['Risk1Y']).codes\n",
    "        X = self.normalizedata(X)\n",
    "        X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        flscores = self.train_models(X_train,y_train,X_test,y_test)\n",
    "        print(flscores)\n",
    "        \n",
    "    def seismicbumps(self):\n",
    "        data = pd.read_csv(\"../Datasets/SeismicBumps/seismic-bumps.arff\",delimiter = ',',names=[\"seismic\",\"seismoacoustic\",\"shift\",\"genergy\",\"gpuls\",\"gdenergy\",\"gdpuls\",\"ghazard\",\"nbumps\",\"nbumps2\",\"nbumps3\",\"nbumps4\",\"nbumps5\",\"nbumps6\",\"nbumps7\",\"nbumps89\",\"energy\",\"maxenergy\",\"class\"])\n",
    "        data.head()\n",
    "        #Preprocessing\n",
    "        X = pd.DataFrame(data,columns=[\"seismic\",\"seismoacoustic\",\"shift\",\"genergy\",\"gpuls\",\"gdenergy\",\"gdpuls\",\"ghazard\",\"nbumps\",\"nbumps2\",\"nbumps3\",\"nbumps4\",\"nbumps5\",\"nbumps6\",\"nbumps7\",\"nbumps89\",\"energy\",\"maxenergy\"])\n",
    "        cat = [\"seismic\",\"seismoacoustic\",\"shift\",\"ghazard\"]\n",
    "        for i in cat:\n",
    "            X[i] = pd.Categorical(X[i]).codes\n",
    "        y = data.iloc[:,18:29]\n",
    "        y['class'] = pd.Categorical(y['class']).codes\n",
    "        X = self.normalizedata(X)\n",
    "        X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        flscores = self.train_models(X_train,y_train,X_test,y_test)\n",
    "        print(flscores)\n",
    "        \n",
    "    def steel_plates_faults(self):\n",
    "        long_list= ['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas', 'Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
    "        data = pd.read_csv(\"../Datasets/SteelPlatesFaults/Faults.NNA\",delimiter = '\\s+',names=long_list)\n",
    "        X = pd.DataFrame(data,columns=['X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas', 'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300', 'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index', 'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index', 'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index', 'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas'])\n",
    "        y = data.iloc[:,27:34]\n",
    "        #Converting 7 columns into one y 'class' column\n",
    "        def fun1(x):\n",
    "            for i in range(len(x)):\n",
    "                if x[i] == 1:\n",
    "                    return i\n",
    "        y1= []        \n",
    "        for j in range(len(y)):        \n",
    "            y1.append((fun1(y.iloc[j]))) \n",
    "        y2 = pd.DataFrame(y1)\n",
    "        y2.columns=['Class']\n",
    "        y=y2\n",
    "        X = self.normalizedata(X)\n",
    "        X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        flscores = self.train_models(X_train,y_train,X_test,y_test)\n",
    "        print(flscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "colab_type": "code",
    "id": "8wX73CRexW6A",
    "outputId": "31a57c25-01cf-484c-a0fd-15e5ba811e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing outliers , rows -  30000\n",
      "After removing outliers , rows - 26429\n",
      "Number of records deleted -  3571\n",
      "Normalization done\n",
      "(18500, 23)\n",
      "(7929, 23)\n",
      "(18500, 1)\n",
      "(7929, 1)\n",
      "Knn Grid Search Starting...\n",
      "KNN  report\n",
      "-------------------------------------\n",
      " \n",
      " Confusion Matrix  [[5785  395]\n",
      " [1158  591]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.94      0.88      6180\n",
      "         1.0       0.60      0.34      0.43      1749\n",
      "\n",
      "    accuracy                           0.80      7929\n",
      "   macro avg       0.72      0.64      0.66      7929\n",
      "weighted avg       0.78      0.80      0.78      7929\n",
      "\n",
      " \n",
      "-------------------------------------\n",
      " \n",
      "Best Hyperparameters {'n_neighbors': 9} Best Score: 0.798\n",
      "Logistic Regression classification Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score : 0.8120822297893807\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "randomForest() missing 1 required positional argument: 'inp_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b42edcf926f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mentrypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentryPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mentrypoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreditCardDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-7be2cc449751>\u001b[0m in \u001b[0;36mcreditCardDataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mflscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7be2cc449751>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(self, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknn_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: randomForest() missing 1 required positional argument: 'inp_params'"
     ]
    }
   ],
   "source": [
    "entrypoint = entryPoint()\n",
    "entrypoint.creditCardDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "General_Program_for_all.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
