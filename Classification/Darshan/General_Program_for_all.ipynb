{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "General_Program_for_all.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M672TMuWxHmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "class entryPoint():\n",
        "\n",
        "  def printaccuracy(self,y_test,predict,model):\n",
        "    print(model,\" report\")\n",
        "    print(\"-------------------------------------\")\n",
        "    print(\" \")\n",
        "    print(\" Confusion Matrix \" ,confusion_matrix(y_test,predict))\n",
        "    print(classification_report(y_test,predict))\n",
        "    print(\" \")\n",
        "    print(\"-------------------------------------\")\n",
        "    print(\" \")\n",
        "    \n",
        "  def normalizedata(self,X):\n",
        "    SS = StandardScaler()\n",
        "    X = SS.fit_transform(X)\n",
        "    print(\"Normalization done\")\n",
        "    return X\n",
        "\t\n",
        "\t\n",
        "  def removeoutliers(self,data,inplace=False):\n",
        "    prev_rows = len(data)\n",
        "    data_copy = data.copy()\n",
        "    z_score = np.abs(stats.zscore(data_copy))\n",
        "    data_copy = data_copy[(z_score < 3).all(axis=1)]\n",
        "    if inplace:\n",
        "      data=data_copy\n",
        "    print(\"Before removing outliers , rows - \", prev_rows)\n",
        "    print(\"After removing outliers , rows -\", len(data_copy))\n",
        "    print(\"Number of records deleted - \", (prev_rows - len(data_copy)))\n",
        "    return data_copy\n",
        "\n",
        "  def train_split(self,X,y,test_size=0.2,random_state=0):\n",
        "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  def knn(self,X_train,y_train,X_test,y_test):\n",
        "    print(\"Knn\")\n",
        "    knn_error = []\n",
        "    for i in range(2,10):\n",
        "      knn = KNeighborsClassifier(n_neighbors=i)\n",
        "      knn.fit(X_train,y_train)\n",
        "      knn_predict= knn.predict(X_test)\n",
        "      print(type(knn_predict))\n",
        "      print(type(y_test))\n",
        "      knn_error.append(np.mean(y_test!=knn_predict))\n",
        "    plt.plot(range(2,50),knn_error)\n",
        "    plt.xlabel(\"K value\")\n",
        "    plt.ylabel(\"Error\")\n",
        "\t\n",
        "  def knn_grid_search(self,X_train,y_train,X_test,y_test,crosVali):\n",
        "    print(\"Knn Grid Search Starting...\")\n",
        "    neighbors={'n_neighbors':np.array(range(10,100,30))}\n",
        "    knn_grid=GridSearchCV(KNeighborsClassifier(),neighbors,verbose=False,refit=True,cv=crosVali)\n",
        "    knn_grid.fit(X_train,y_train)\n",
        "    knn_predict = knn_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,knn_predict,\"KNN\")\n",
        "    print(\"Best Hyperparameters \" + str(knn_grid.best_params_) + \" Best Score: \" + str(knn_grid.best_score_))\n",
        "    flScore = f1_score(y_test,knn_predict)\n",
        "    return flScore\n",
        "    \n",
        "  def logisticRegression(self,X_train,y_train,X_test,y_test):\n",
        "    print(\"Logistic Regression classification Starting...\")\n",
        "    Co_reg= np.logspace(-4, 4, 20)\n",
        "    penalty_reg = ['l1','l2']\n",
        "    max_iteration = [10,100,1000]\n",
        "    score = []\n",
        "    for pen in penalty_reg:\n",
        "      for i in Co_reg:\n",
        "        for it in max_iteration:\n",
        "          clf = LogisticRegression(random_state=0, solver='liblinear', penalty=pen , C=i, max_iter=it).fit(X_train, y_train.values.ravel())\n",
        "          score.append(clf.score(X_test, y_test.values.ravel()))\n",
        "    \n",
        "    print(\"Best Score : \" + str(max(score)))\n",
        "        \n",
        "  def svm_model(self,X_train,y_train,X_test,y_test,inp_params,croVali):\n",
        "    print(\"SVM Classification Starting...\")\n",
        "    svm = SVC(kernel='rbf',random_state=0)\t\n",
        "    params = inp_params\n",
        "    svm_grid = GridSearchCV(svm, params, verbose=1,return_train_score=True)\n",
        "    svm_grid.fit(X_train,y_train.ravel())\n",
        "    svm_predict = svm_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,svm_predict,\"SVM\")\n",
        "    print(\"Best Hyperparameters \" + str(svm_grid.best_params_) + \" Best Score: \" + str(svm_grid.best_score_))\n",
        "    return f1_score(y_test,svm_predict)\n",
        "\t\t\n",
        "  def decisionTreeClassifier(self,X_train,y_train,X_test,y_test,inp_params):\n",
        "    print(\"Decisiontree Classifier Starting...\")\n",
        "    params = inp_params\n",
        "    decisionTree_grid = GridSearchCV(DecisionTreeClassifier(), params, verbose=1, cv=3,return_train_score=True)\n",
        "    decisionTree_grid.fit(X_train,y_train.ravel())\n",
        "    decisionTree_predict = decisionTree_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,decisionTree_predict,\"DecisionTree\")\n",
        "    print(\"Best Hyperparameters \" + str(decisionTree_predict.best_params_) + \" Best Score: \" + str(decisionTree_predict.best_score_))\n",
        "    return f1_score(y_test,decisionTree_predict)\n",
        "    \n",
        "  def randomForest(self,X_train,y_train,X_test,y_test,inp_params):\n",
        "    print(\"randomForest Classifier Starting...\")\n",
        "    rf = RandomForestClassifier()\n",
        "    params = inp_params\n",
        "    rf_grid = GridSearchCV(rf, params, verbose=1, cv=3)\n",
        "    rf_grid.fit(X_train,y_train.ravel())\n",
        "    rf_predict = rf_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,rf_predict,\"RandomForest\")\n",
        "    print(\"Best Hyperparameters \" + str(rf_grid.best_params_) + \" Best Score: \" + str(rf_grid.best_score_))\n",
        "    return f1_score(y_test,rf_predict)\n",
        "    \n",
        "  def adaBoost(self,X_train,y_train,X_test,y_test,inp_params):\n",
        "    print(\"AdaBoost Classifier Starting...\")\n",
        "    ab = AdaBoostClassifier()\n",
        "    params = inp_params\n",
        "    ab_grid = GridSearchCV(ab, params, verbose=1, cv=3)\n",
        "    ab_grid.fit(X_train,y_train)\n",
        "    ab_predict = ab_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,ab_predict,\"AdaBoost\")\n",
        "    print(\"Best Hyperparameters \" + str(ab_grid.best_params_) + \" Best Score: \" + str(ab_grid.best_score_))\n",
        "    return f1_score(y_test,ab_predict)\n",
        "    \n",
        "  def gaussianNaiveBaive(self,X_train,y_train,X_test,y_test):\n",
        "    print(\"GaussianNaiveBaive Classifier Starting... \")\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train,y_train)\n",
        "    gnb_predict = gnb.predict(X_test)\n",
        "    self.printaccuracy(y_test,gnb_predict,\"Naive Bayes\")\n",
        "    return f1_score(y_test,gnb_predict)\n",
        "\t\t\n",
        "  def neuralNetworks(self,X_train,y_train,X_test,y_test,inp_params):\n",
        "    print(\"NeuralNetworks Classifier Starting...\")\n",
        "    nn = MLPClassifier(solver='sgd',random_state=0)\n",
        "    params = inp_params\n",
        "    nn_grid = GridSearchCV(nn, params, cv=3)\n",
        "    nn_grid.fit(X_train,y_train)\n",
        "    nn_predict = nn_grid.predict(X_test)\n",
        "    self.printaccuracy(y_test,nn_predict,\"Neural Networks\")\n",
        "    print(\"Best Hyperparameters \" + str(nn_grid.best_params_) + \" Best Score: \" + str(nn_grid.best_score_))\n",
        "    return f1_score(y_test,nn_predict)\n",
        "\n",
        "  def train_models(self,X_train,y_train,X_test,y_test,svm_params,decisiontree_params,random_forest,adaboost_params,nn_params):\n",
        "    f1scores = []\n",
        "    #f1scores.append(self.knn(X_train,y_train,X_test,y_test))\n",
        "    #f1scores.append(self.knn_grid_search(X_train,y_train,X_test,y_test,2))\n",
        "    f1scores.append(self.svm_model(X_train,y_train,X_test,y_test,svm_params,2))\n",
        "    return f1scores\n",
        "\n",
        "  def creditCardDataset(self):\n",
        "    #For credit card Defaulters \n",
        "    df = pd.read_csv(\"credit.csv\")\n",
        "    df.drop(df.columns[0], axis=1, inplace=True)\n",
        "    df.dropna(axis=0, inplace=True)\n",
        "    df = df.iloc[1:]\n",
        "    df = df.astype(float)\n",
        "    df = self.removeoutliers(df,inplace=True)\n",
        "    X = df.iloc[:,:23]\n",
        "    y = df.iloc[:,23:24]\n",
        "    X = entrypoint.normalizedata(X)\n",
        "    X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
        "    svm_params = { 'C' : np.logspace(0, 3, 4), 'gamma' : np.logspace(-2, 1, 4)}\n",
        "    decisiontree_params = {'max_depth' : np.linspace(1, 10, 10, endpoint=True),'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)}\n",
        "    random_forest_params = {'n_estimators' : np.linspace(10,100,10),'max_depth' : np.linspace(1,6,2)}\n",
        "    adaBoost_params = {'n_estimators' : np.linspace(10,100,10)}\n",
        "    nn_params = {'hidden_layer_sizes': np.arange(30,150,20),'learning_rate': ['constant','invscaling','adaptive'],'max_iter': np.arange(20,200,50)}\n",
        "    flscores = self.train_models(X_train,y_train.values.ravel(),X_test,y_test.values.ravel(),svm_params,decisiontree_params,random_forest_params,\n",
        "                                 adaBoost_params,nn_params)\n",
        "    print(flscores)\n",
        "\t\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wX73CRexW6A",
        "colab_type": "code",
        "outputId": "21e6220f-af54-424b-d9de-558591c3bf7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "entrypoint = entryPoint()\n",
        "entrypoint.creditCardDataset()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before removing outliers , rows -  30000\n",
            "After removing outliers , rows - 26429\n",
            "Number of records deleted -  3571\n",
            "Normalization done\n",
            "81.3% training accuracy for C=1.0 gamma=0.01\n",
            "81.4% training accuracy for C=1.0 gamma=0.10\n",
            "78.7% training accuracy for C=1.0 gamma=1.00\n",
            "77.5% training accuracy for C=1.0 gamma=10.00\n",
            "81.5% training accuracy for C=10.0 gamma=0.01\n",
            "79.5% training accuracy for C=10.0 gamma=0.10\n",
            "76.3% training accuracy for C=10.0 gamma=1.00\n",
            "76.9% training accuracy for C=10.0 gamma=10.00\n",
            "81.5% training accuracy for C=100.0 gamma=0.01\n",
            "76.6% training accuracy for C=100.0 gamma=0.10\n",
            "74.7% training accuracy for C=100.0 gamma=1.00\n",
            "76.8% training accuracy for C=100.0 gamma=10.00\n",
            "80.4% training accuracy for C=1000.0 gamma=0.01\n",
            "73.3% training accuracy for C=1000.0 gamma=0.10\n",
            "74.2% training accuracy for C=1000.0 gamma=1.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b42edcf926f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mentrypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentryPoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mentrypoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreditCardDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-cec2fefda8bf>\u001b[0m in \u001b[0;36mcreditCardDataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mnn_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'hidden_layer_sizes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'invscaling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'adaptive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_iter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     flscores = self.train_models(X_train,y_train.values.ravel(),X_test,y_test.values.ravel(),svm_params,decisiontree_params,random_forest_params,\n\u001b[0;32m--> 192\u001b[0;31m                                  adaBoost_params,nn_params)\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-cec2fefda8bf>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(self, X_train, y_train, X_test, y_test, svm_params, decisiontree_params, random_forest, adaboost_params, nn_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m#f1scores.append(self.knn(X_train,y_train,X_test,y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m#f1scores.append(self.knn_grid_search(X_train,y_train,X_test,y_test,2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mf1scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msvm_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-cec2fefda8bf>\u001b[0m in \u001b[0;36msvm_model\u001b[0;34m(self, X_train, y_train, X_test, y_test, inp_params, croVali)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.1f%% training accuracy for C=%.1f gamma=%.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}