{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gursimransingh/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py:702: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "long_list = pd.read_csv(\"../Datasets/sgemm_product_dataset/sgemm_product.csv\",delimiter=',',nrows=1)\n",
    "data = pd.read_csv(\"../Datasets/sgemm_product_dataset/sgemm_product.csv\",delimiter = ',',names=long_list,skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run1 (ms)</th>\n",
       "      <th>Run2 (ms)</th>\n",
       "      <th>Run3 (ms)</th>\n",
       "      <th>Run4 (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.26</td>\n",
       "      <td>115.87</td>\n",
       "      <td>118.55</td>\n",
       "      <td>115.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.13</td>\n",
       "      <td>78.25</td>\n",
       "      <td>79.25</td>\n",
       "      <td>79.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.84</td>\n",
       "      <td>80.69</td>\n",
       "      <td>80.76</td>\n",
       "      <td>80.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.32</td>\n",
       "      <td>89.90</td>\n",
       "      <td>86.75</td>\n",
       "      <td>85.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115.13</td>\n",
       "      <td>121.98</td>\n",
       "      <td>122.73</td>\n",
       "      <td>114.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.10</td>\n",
       "      <td>82.41</td>\n",
       "      <td>87.01</td>\n",
       "      <td>82.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.31</td>\n",
       "      <td>82.86</td>\n",
       "      <td>88.60</td>\n",
       "      <td>82.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.13</td>\n",
       "      <td>94.30</td>\n",
       "      <td>96.19</td>\n",
       "      <td>94.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>117.38</td>\n",
       "      <td>116.95</td>\n",
       "      <td>124.15</td>\n",
       "      <td>117.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85.76</td>\n",
       "      <td>85.30</td>\n",
       "      <td>86.96</td>\n",
       "      <td>87.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83.48</td>\n",
       "      <td>83.46</td>\n",
       "      <td>84.44</td>\n",
       "      <td>84.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>87.08</td>\n",
       "      <td>85.97</td>\n",
       "      <td>87.09</td>\n",
       "      <td>87.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>118.71</td>\n",
       "      <td>117.23</td>\n",
       "      <td>118.61</td>\n",
       "      <td>118.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91.28</td>\n",
       "      <td>92.42</td>\n",
       "      <td>92.42</td>\n",
       "      <td>93.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>85.89</td>\n",
       "      <td>85.37</td>\n",
       "      <td>86.58</td>\n",
       "      <td>86.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105.16</td>\n",
       "      <td>105.95</td>\n",
       "      <td>106.29</td>\n",
       "      <td>106.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>76.79</td>\n",
       "      <td>76.73</td>\n",
       "      <td>77.86</td>\n",
       "      <td>77.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64.64</td>\n",
       "      <td>64.23</td>\n",
       "      <td>65.77</td>\n",
       "      <td>65.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>71.62</td>\n",
       "      <td>71.55</td>\n",
       "      <td>72.51</td>\n",
       "      <td>72.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64.21</td>\n",
       "      <td>63.26</td>\n",
       "      <td>63.70</td>\n",
       "      <td>64.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76.78</td>\n",
       "      <td>76.71</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>65.37</td>\n",
       "      <td>64.81</td>\n",
       "      <td>65.77</td>\n",
       "      <td>65.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>70.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>71.09</td>\n",
       "      <td>71.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>62.69</td>\n",
       "      <td>62.68</td>\n",
       "      <td>64.09</td>\n",
       "      <td>63.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>78.74</td>\n",
       "      <td>78.42</td>\n",
       "      <td>79.78</td>\n",
       "      <td>79.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70.46</td>\n",
       "      <td>69.84</td>\n",
       "      <td>69.69</td>\n",
       "      <td>70.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75.40</td>\n",
       "      <td>74.62</td>\n",
       "      <td>75.99</td>\n",
       "      <td>75.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>76.73</td>\n",
       "      <td>74.15</td>\n",
       "      <td>76.63</td>\n",
       "      <td>74.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78.91</td>\n",
       "      <td>78.64</td>\n",
       "      <td>79.78</td>\n",
       "      <td>79.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>69.74</td>\n",
       "      <td>69.29</td>\n",
       "      <td>70.46</td>\n",
       "      <td>69.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241570</th>\n",
       "      <td>27.73</td>\n",
       "      <td>27.74</td>\n",
       "      <td>27.72</td>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241571</th>\n",
       "      <td>19.65</td>\n",
       "      <td>19.51</td>\n",
       "      <td>19.51</td>\n",
       "      <td>19.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241572</th>\n",
       "      <td>36.43</td>\n",
       "      <td>36.38</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241573</th>\n",
       "      <td>35.26</td>\n",
       "      <td>35.27</td>\n",
       "      <td>35.26</td>\n",
       "      <td>35.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241574</th>\n",
       "      <td>29.19</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.19</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241575</th>\n",
       "      <td>18.21</td>\n",
       "      <td>18.04</td>\n",
       "      <td>18.05</td>\n",
       "      <td>18.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241576</th>\n",
       "      <td>36.16</td>\n",
       "      <td>36.15</td>\n",
       "      <td>36.17</td>\n",
       "      <td>36.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241577</th>\n",
       "      <td>36.55</td>\n",
       "      <td>36.58</td>\n",
       "      <td>36.58</td>\n",
       "      <td>36.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241578</th>\n",
       "      <td>27.72</td>\n",
       "      <td>27.75</td>\n",
       "      <td>27.71</td>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241579</th>\n",
       "      <td>19.64</td>\n",
       "      <td>19.51</td>\n",
       "      <td>19.51</td>\n",
       "      <td>19.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241580</th>\n",
       "      <td>36.40</td>\n",
       "      <td>36.37</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241581</th>\n",
       "      <td>35.26</td>\n",
       "      <td>35.26</td>\n",
       "      <td>35.26</td>\n",
       "      <td>35.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241582</th>\n",
       "      <td>29.19</td>\n",
       "      <td>29.22</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241583</th>\n",
       "      <td>18.04</td>\n",
       "      <td>17.90</td>\n",
       "      <td>17.89</td>\n",
       "      <td>17.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241584</th>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241585</th>\n",
       "      <td>35.37</td>\n",
       "      <td>35.36</td>\n",
       "      <td>35.37</td>\n",
       "      <td>35.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241586</th>\n",
       "      <td>28.84</td>\n",
       "      <td>28.87</td>\n",
       "      <td>28.82</td>\n",
       "      <td>28.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241587</th>\n",
       "      <td>17.92</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.76</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241588</th>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241589</th>\n",
       "      <td>35.37</td>\n",
       "      <td>35.36</td>\n",
       "      <td>35.37</td>\n",
       "      <td>35.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241590</th>\n",
       "      <td>28.45</td>\n",
       "      <td>28.49</td>\n",
       "      <td>28.41</td>\n",
       "      <td>28.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241591</th>\n",
       "      <td>17.91</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241592</th>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241593</th>\n",
       "      <td>35.26</td>\n",
       "      <td>35.27</td>\n",
       "      <td>35.27</td>\n",
       "      <td>35.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241594</th>\n",
       "      <td>28.84</td>\n",
       "      <td>28.87</td>\n",
       "      <td>28.83</td>\n",
       "      <td>28.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241595</th>\n",
       "      <td>17.96</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241596</th>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241597</th>\n",
       "      <td>35.28</td>\n",
       "      <td>34.82</td>\n",
       "      <td>35.27</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241598</th>\n",
       "      <td>28.43</td>\n",
       "      <td>28.49</td>\n",
       "      <td>28.44</td>\n",
       "      <td>28.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241599</th>\n",
       "      <td>17.94</td>\n",
       "      <td>17.79</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Run1 (ms)  Run2 (ms)  Run3 (ms)  Run4 (ms)\n",
       "0          115.26     115.87     118.55     115.80\n",
       "1           78.13      78.25      79.25      79.19\n",
       "2           79.84      80.69      80.76      80.97\n",
       "3           84.32      89.90      86.75      85.58\n",
       "4          115.13     121.98     122.73     114.81\n",
       "5           81.10      82.41      87.01      82.14\n",
       "6           83.31      82.86      88.60      82.97\n",
       "7           93.13      94.30      96.19      94.43\n",
       "8          117.38     116.95     124.15     117.83\n",
       "9           85.76      85.30      86.96      87.19\n",
       "10          83.48      83.46      84.44      84.38\n",
       "11          87.08      85.97      87.09      87.23\n",
       "12         118.71     117.23     118.61     118.55\n",
       "13          91.28      92.42      92.42      93.40\n",
       "14          85.89      85.37      86.58      86.83\n",
       "15         105.16     105.95     106.29     106.58\n",
       "16          76.79      76.73      77.86      77.84\n",
       "17          64.64      64.23      65.77      65.83\n",
       "18          71.62      71.55      72.51      72.60\n",
       "19          64.21      63.26      63.70      64.39\n",
       "20          76.78      76.71      77.83      77.79\n",
       "21          65.37      64.81      65.77      65.78\n",
       "22          70.00      70.00      71.09      71.05\n",
       "23          62.69      62.68      64.09      63.27\n",
       "24          78.74      78.42      79.78      79.82\n",
       "25          70.46      69.84      69.69      70.93\n",
       "26          75.40      74.62      75.99      75.84\n",
       "27          76.73      74.15      76.63      74.84\n",
       "28          78.91      78.64      79.78      79.80\n",
       "29          69.74      69.29      70.46      69.79\n",
       "...           ...        ...        ...        ...\n",
       "241570      27.73      27.74      27.72      27.70\n",
       "241571      19.65      19.51      19.51      19.51\n",
       "241572      36.43      36.38      36.40      36.40\n",
       "241573      35.26      35.27      35.26      35.26\n",
       "241574      29.19      29.22      29.19      29.18\n",
       "241575      18.21      18.04      18.05      18.05\n",
       "241576      36.16      36.15      36.17      36.17\n",
       "241577      36.55      36.58      36.58      36.57\n",
       "241578      27.72      27.75      27.71      27.70\n",
       "241579      19.64      19.51      19.51      19.51\n",
       "241580      36.40      36.37      36.40      36.39\n",
       "241581      35.26      35.26      35.26      35.26\n",
       "241582      29.19      29.22      29.18      29.18\n",
       "241583      18.04      17.90      17.89      17.89\n",
       "241584      36.04      36.03      36.03      36.04\n",
       "241585      35.37      35.36      35.37      35.36\n",
       "241586      28.84      28.87      28.82      28.82\n",
       "241587      17.92      17.77      17.76      17.77\n",
       "241588      36.04      36.03      36.04      36.04\n",
       "241589      35.37      35.36      35.37      35.37\n",
       "241590      28.45      28.49      28.41      28.44\n",
       "241591      17.91      17.77      17.77      17.77\n",
       "241592      36.04      36.03      36.04      36.04\n",
       "241593      35.26      35.27      35.27      35.26\n",
       "241594      28.84      28.87      28.83      28.83\n",
       "241595      17.96      17.77      17.77      17.77\n",
       "241596      36.04      36.03      36.04      36.03\n",
       "241597      35.28      34.82      35.27      35.27\n",
       "241598      28.43      28.49      28.44      28.45\n",
       "241599      17.94      17.79      17.77      17.77\n",
       "\n",
       "[241600 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data,columns=['MWG','NWG','KWG','MDIMC','NDIMC','MDIMA','NDIMB','KWI','VWM','VWN','STRM','STRN','SA','SB'])\n",
    "y = pd.DataFrame(data,columns=['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModels():\n",
    "\n",
    "\n",
    "  def scores(self,y_test,y_pred, model):\n",
    "    print(\"Variance Score : \" , explained_variance_score(y_test, y_pred))\n",
    "    print(\"R2 Score : \" ,r2_score(y_test,y_pred))\n",
    "    print(\"Root Mean Square : \",math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"Best Parameters : \", model.best_params_ )\n",
    "\n",
    "  def svmRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------SVM Regression Starts------------\\n\\n \")\n",
    "    clf = SVR()\n",
    "    svm_grid = GridSearchCV(clf, params, verbose=False, cv=3,return_train_score=True)\n",
    "    svm_grid.fit(X_train,y_train)\n",
    "    svm_predict = svm_grid.predict(X_test)\n",
    "    print(\"Best Parameters : \", svm_grid.best_params_ )\n",
    "    self.scores(Y_test, svm_predict, svm_grid)\n",
    "    print(\"\\n-----------SVM Regression ends------------\\n\\n \")\n",
    "\n",
    "  def decisionTreeRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Decision Tree Regression Starts------------\\n\\n\")\n",
    "    DTregressor = DecisionTreeRegressor(random_state=0)\n",
    "    DT_grid = GridSearchCV(DTregressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    DT_grid.fit(X_train,y_train)\n",
    "    DT_predict = DT_grid.predict(X_test)\n",
    "    self.scores(Y_test, DT_predict, DT_grid)\n",
    "    print(\"\\n-----------Decision Tree Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def randomForestRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Random Forest Regression Starts------------\\n\\n\")\n",
    "    RFRegressor = RandomForestRegressor(random_state=0)\n",
    "    RF_grid = GridSearchCV(RFRegressor, params, verbose=False, cv=3, return_train_score=True)\n",
    "    RF_grid.fit(X_train,y_train)\n",
    "    RF_predict = RF_grid.predict(X_test)\n",
    "    self.scores(Y_test, RF_predict, RF_grid)\n",
    "    print(\"\\n-----------Random Forest Regression Ends------------\\n\\n\")\n",
    "  \n",
    "  def adaBoostRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------AdaBoost Regression Starts------------\\n\\n\")\n",
    "    AdaRegressor = AdaBoostRegressor(random_state=0)\n",
    "    adaBoost_grid = GridSearchCV(AdaRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    adaBoost_grid.fit(X_train,y_train)\n",
    "    adaBoost_predict = adaBoost_grid.predict(X_test)\n",
    "    self.scores(Y_test, adaBoost_predict, adaBoost_grid)\n",
    "    print(\"\\n-----------AdaBoost Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def gaussianProcessRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------GaussianProcess Regression Starts------------\\n\\n\")\n",
    "    GPRRegressor = GaussianProcessRegressor(random_state=0)\n",
    "    GPR_grid = GridSearchCV(GPRRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    GPR_grid.fit(X_train,y_train)\n",
    "    GPR_predict = GPR_grid.predict(X_test)\n",
    "    self.scores(Y_test, GPR_predict, GPR_grid)\n",
    "    print(\"\\n-----------GaussianProcess Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def LinearRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Linear Regression Starts------------\\n\\n\")\n",
    "    LinearRegressor = LinearRegression()\n",
    "    linearRegression_grid = GridSearchCV(LinearRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    linearRegression_grid.fit(X_train,y_train)\n",
    "    linearRegression_predict = linearRegression_grid.predict(X_test)\n",
    "    self.scores(Y_test, linearRegression_predict, linearRegression_grid)\n",
    "    print(\"\\n-----------Linear Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def mlpRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Neural Network Regression Starts------------\\n\\n\")\n",
    "    MLPRegressor_obj = MLPRegressor(random_state=0)\n",
    "    MLPRegressor_grid = GridSearchCV(MLPRegressor_obj, params, verbose=False, cv=3,return_train_score=True)\n",
    "    MLPRegressor_grid.fit(X_train,y_train)\n",
    "    MLPRegressor_predict = MLPRegressor_grid.predict(X_test)\n",
    "    self.scores(Y_test, MLPRegressor_predict, MLPRegressor_grid)\n",
    "    print(\"\\n-----------Neural Network Regression Ends------------\\n\\n\")\n",
    "    \n",
    "\n",
    "  def train_split(self,X,y,test_size=0.2,random_state=0):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    return X_train,X_test,y_train,y_test\n",
    " \n",
    "  def train_all__models(self, X, y):\n",
    "    svm_regression_params =  { 'C' : np.logspace(0, 3, 4), 'gamma' : np.logspace(-2, 1, 4)}\n",
    "    dt_params = {'max_depth' : np.arange(1, 10, 10),'min_samples_split': np.arange(0.1, 1.0, 10)}\n",
    "    rd_params = {'n_estimators' : np.arange(10,100,10),'max_depth' : np.arange(1,6,2)}\n",
    "    ada_params = {'n_estimators' : np.arange(10,100,10)}\n",
    "    gpr_params = {'n_restarts_optimizer' : np.arange(1,10,1)}\n",
    "    linear_params = {'n_jobs' : np.arange(1,5,1)}\n",
    "    mlp_params = {'hidden_layer_sizes': np.arange(30,150,20),'learning_rate': ['constant','invscaling','adaptive'],'max_iter': np.arange(20,200,50)}\n",
    "    X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "    self.svmRegression(X_train,X_test,y_train,y_test, svm_regression_params)\n",
    "    self.decisionTreeRegression(X_train,X_test,y_train,y_test, dt_params)\n",
    "    self.randomForestRegression(X_train,X_test,y_train,y_test, rd_params)\n",
    "    self.adaBoostRegression(X_train,X_test,y_train,y_test, ada_params)\n",
    "    self.gaussianProcessRegression(X_train,X_test,y_train,y_test, gpr_params)\n",
    "    self.LinearRegression(X_train,X_test,y_train,y_test, linear_params)\n",
    "    self.mlpRegression(X_train,X_test,y_train,y_test, mlp_params)\n",
    "\n",
    "  def wine_quality(self):\n",
    "    df = pd.read_csv('../Datasets/Wine Quality/winequality-red.csv',delimiter=';')\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    #print(df.corr()['quality'].drop('quality'))\n",
    "    X = df[df.columns[0:11]]\n",
    "    y = df[df.columns[11:12]]\n",
    "    self.train_all__models(X, y.values.ravel())\n",
    "\n",
    "  def communities(self):\n",
    "    columns_data = ['state','county','community','communityname','fold','population','householdsize','racepctblack','racePctWhite','racePctAsian','racePctHisp','agePct12t21',\n",
    "                    'agePct12t29','agePct16t24','agePct65up','numbUrban','pctUrban','medIncome','pctWWage','pctWFarmSelf','pctWInvInc','pctWSocSec','pctWPubAsst','pctWRetire','medFamInc',\n",
    "                    'perCapInc','whitePerCap','blackPerCap','indianPerCap','AsianPerCap','OtherPerCap','HispPerCap','NumUnderPov','PctPopUnderPov','PctLess9thGrade',\n",
    "                    'PctNotHSGrad','PctBSorMore','PctUnemployed','PctEmploy','PctEmplManu','PctEmplProfServ','PctOccupManu','PctOccupMgmtProf','MalePctDivorce','MalePctNevMarr',\n",
    "                    'FemalePctDiv','TotalPctDiv','PersPerFam','PctFam2Par','PctKids2Par','PctYoungKids2Par','PctTeen2Par','PctWorkMomYoungKids','PctWorkMom','NumIlleg','PctIlleg',\n",
    "                    'NumImmig','PctImmigRecent','PctImmigRec5','PctImmigRec8','PctImmigRec10','PctRecentImmig','PctRecImmig5','PctRecImmig8','PctRecImmig10','PctSpeakEnglOnly','PctNotSpeakEnglWell'\n",
    "                    ,'PctLargHouseFam','PctLargHouseOccup','PersPerOccupHous','PersPerOwnOccHous','PersPerRentOccHous','PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR',\n",
    "                    'MedNumBR','HousVacant','PctHousOccup','PctHousOwnOcc','PctVacantBoarded','PctVacMore6Mos','MedYrHousBuilt','PctHousNoPhone','PctWOFullPlumb','OwnOccLowQuart','OwnOccMedVal',\n",
    "                    'OwnOccHiQuart','RentLowQ','RentMedian','RentHighQ','MedRent','MedRentPctHousInc','MedOwnCostPctInc','MedOwnCostPctIncNoMtg','NumInShelters','NumStreet','PctForeignBorn',\n",
    "                    'PctBornSameState','PctSameHouse85','PctSameCity85','PctSameState85','LemasSwornFT','LemasSwFTPerPop','LemasSwFTFieldOps','LemasSwFTFieldPerPop','LemasTotalReq','LemasTotReqPerPop',\n",
    "                    'PolicReqPerOffic','PolicPerPop','RacialMatchCommPol','PctPolicWhite','PctPolicBlack','PctPolicHisp','PctPolicAsian','PctPolicMinor','OfficAssgnDrugUnits','NumKindsDrugsSeiz',\n",
    "                    'PolicAveOTWorked','LandArea','PopDens','PctUsePubTrans','PolicCars','PolicOperBudg','LemasPctPolicOnPatr','LemasGangUnitDeploy','LemasPctOfficDrugUn','PolicBudgPerPop',\n",
    "                    'ViolentCrimesPerPop'\n",
    "                    ]\n",
    "    df = pd.read_csv('communities.data',delimiter=',',names=columns_data)\n",
    "\n",
    "    #print(\"Before Removing the Non Predictable Features \\n\")\n",
    "    #print(\"Shape Before Removing :\" +str(df.shape) + \"\\n\")\n",
    "    #print(df.head())\n",
    "    df = df.replace('?',np.nan)\n",
    "    #print(\"After Removing the Non predictable Features \\n \")\n",
    "    #print(\"Shape After Removing :\" + str(df.shape) + \"\\n\")\n",
    "    #print(df.head())\n",
    "    print(\"Before Droping data Shape \" + str(df.shape))\n",
    "    #According to Dataset Description there are 5 non predictive features which can be removed\n",
    "    df = df.drop(['fold','community','state','communityname','county'],axis=1)\n",
    "\n",
    "    print(\"Checking the Columns Containing the null Values\")\n",
    "    \n",
    "    #for i in range(0,120,41):\n",
    "    #  print(df.iloc[:,i:i+41].isna().sum())\n",
    "    #  print(\"\\n\")\n",
    "    median_value = df.iloc[:,25].median(skipna = True)\n",
    "    df.iloc[130,25] = median_value\n",
    "    \n",
    "    df = df.dropna(axis=1)\n",
    "    print(df.columns)\n",
    "    print(\"After Droping data Shape \" + str(df.shape))\n",
    "    #Replacing the columns with median\n",
    "  \n",
    "\n",
    "    print(\"Number of Missing Values in column is \" + str(df.iloc[:,25].isna().sum()))\n",
    "    print(df.shape)\n",
    "    X = df[df.columns[0:100]]\n",
    "    y = df[df.columns[100:101]]\n",
    "    print(X.describe())\n",
    "    #print(y)\n",
    "    #print(X.head())\n",
    "    self.train_all__models(X, y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------SVM Regression Starts------------\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "regressionModels = RegressionModels()\n",
    "for i in range(4):\n",
    "    regressionModels.train_all__models(X, y.iloc[:,i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
