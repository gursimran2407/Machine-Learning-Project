{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pqGoSsuAAgZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkJiN_c1Bfqz"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-9ddbc209d12a>, line 155)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-9ddbc209d12a>\"\u001b[1;36m, line \u001b[1;32m155\u001b[0m\n\u001b[1;33m    def speech_data(self):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class RegressionModels():\n",
    "\n",
    "\n",
    "  def scores(self,y_test,y_pred, model):\n",
    "    print(\"Variance Score : \" , explained_variance_score(y_test, y_pred))\n",
    "    print(\"R2 Score : \" ,r2_score(y_test,y_pred))\n",
    "    print(\"Root Mean Square : \",math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"Best Parameters : \", model.best_params_ )\n",
    "\n",
    "  def svmRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------SVM Regression Starts------------\\n\\n \")\n",
    "    clf = SVR()\n",
    "    svm_grid = GridSearchCV(clf, params, verbose=False, cv=3,return_train_score=True)\n",
    "    svm_grid.fit(X_train,y_train)\n",
    "    svm_predict = svm_grid.predict(X_test)\n",
    "    print(\"Best Parameters : \", svm_grid.best_params_ )\n",
    "    self.scores(Y_test, svm_predict, svm_grid)\n",
    "    print(\"\\n-----------SVM Regression ends------------\\n\\n \")\n",
    "\n",
    "  def decisionTreeRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Decision Tree Regression Starts------------\\n\\n\")\n",
    "    DTregressor = DecisionTreeRegressor(random_state=0)\n",
    "    DT_grid = GridSearchCV(DTregressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    DT_grid.fit(X_train,y_train)\n",
    "    DT_predict = DT_grid.predict(X_test)\n",
    "    self.scores(Y_test, DT_predict, DT_grid)\n",
    "    print(\"\\n-----------Decision Tree Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def randomForestRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Random Forest Regression Starts------------\\n\\n\")\n",
    "    RFRegressor = RandomForestRegressor(random_state=0)\n",
    "    RF_grid = GridSearchCV(RFRegressor, params, verbose=False, cv=3, return_train_score=True)\n",
    "    RF_grid.fit(X_train,y_train)\n",
    "    RF_predict = RF_grid.predict(X_test)\n",
    "    self.scores(Y_test, RF_predict, RF_grid)\n",
    "    print(\"\\n-----------Random Forest Regression Ends------------\\n\\n\")\n",
    "  \n",
    "  def adaBoostRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------AdaBoost Regression Starts------------\\n\\n\")\n",
    "    AdaRegressor = AdaBoostRegressor(random_state=0)\n",
    "    adaBoost_grid = GridSearchCV(AdaRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    adaBoost_grid.fit(X_train,y_train)\n",
    "    adaBoost_predict = adaBoost_grid.predict(X_test)\n",
    "    self.scores(Y_test, adaBoost_predict, adaBoost_grid)\n",
    "    print(\"\\n-----------AdaBoost Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def gaussianProcessRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------GaussianProcess Regression Starts------------\\n\\n\")\n",
    "    GPRRegressor = GaussianProcessRegressor(random_state=0)\n",
    "    GPR_grid = GridSearchCV(GPRRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    GPR_grid.fit(X_train,y_train)\n",
    "    GPR_predict = GPR_grid.predict(X_test)\n",
    "    self.scores(Y_test, GPR_predict, GPR_grid)\n",
    "    print(\"\\n-----------GaussianProcess Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def LinearRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Linear Regression Starts------------\\n\\n\")\n",
    "    LinearRegressor = LinearRegression()\n",
    "    linearRegression_grid = GridSearchCV(LinearRegressor, params, verbose=False, cv=3,return_train_score=True)\n",
    "    linearRegression_grid.fit(X_train,y_train)\n",
    "    linearRegression_predict = linearRegression_grid.predict(X_test)\n",
    "    self.scores(Y_test, linearRegression_predict, linearRegression_grid)\n",
    "    print(\"\\n-----------Linear Regression Ends------------\\n\\n\")\n",
    "\n",
    "  def mlpRegression(self, X_train, X_test, y_train, Y_test, params):\n",
    "    print(\"-----------Neural Network Regression Starts------------\\n\\n\")\n",
    "    MLPRegressor_obj = MLPRegressor(random_state=0)\n",
    "    MLPRegressor_grid = GridSearchCV(MLPRegressor_obj, params, verbose=False, cv=3,return_train_score=True)\n",
    "    MLPRegressor_grid.fit(X_train,y_train)\n",
    "    MLPRegressor_predict = MLPRegressor_grid.predict(X_test)\n",
    "    self.scores(Y_test, MLPRegressor_predict, MLPRegressor_grid)\n",
    "    print(\"\\n-----------Neural Network Regression Ends------------\\n\\n\")\n",
    "    \n",
    "\n",
    "  def train_split(self,X,y,test_size=0.2,random_state=0):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n",
    "    return X_train,X_test,y_train,y_test\n",
    " \n",
    "  def train_all__models(self, X, y):\n",
    "    svm_regression_params =  { 'C' : np.logspace(0, 3, 4), 'gamma' : np.logspace(-2, 1, 4)}\n",
    "    dt_params = {'max_depth' : np.arange(1, 10, 10),'min_samples_split': np.arange(0.1, 1.0, 10)}\n",
    "    rd_params = {'n_estimators' : np.arange(10,100,10),'max_depth' : np.arange(1,6,2)}\n",
    "    ada_params = {'n_estimators' : np.arange(10,100,10)}\n",
    "    gpr_params = {'n_restarts_optimizer' : np.arange(1,10,1)}\n",
    "    linear_params = {'n_jobs' : np.arange(1,5,1)}\n",
    "    mlp_params = {'hidden_layer_sizes': np.arange(30,150,20),'learning_rate': ['constant','invscaling','adaptive'],'max_iter': np.arange(20,200,50)}\n",
    "    X_train,X_test,y_train,y_test = self.train_split(X,y)\n",
    "    self.svmRegression(X_train,X_test,y_train,y_test, svm_regression_params)\n",
    "    self.decisionTreeRegression(X_train,X_test,y_train,y_test, dt_params)\n",
    "    self.randomForestRegression(X_train,X_test,y_train,y_test, rd_params)\n",
    "    self.adaBoostRegression(X_train,X_test,y_train,y_test, ada_params)\n",
    "    self.gaussianProcessRegression(X_train,X_test,y_train,y_test, gpr_params)\n",
    "    self.LinearRegression(X_train,X_test,y_train,y_test, linear_params)\n",
    "    self.mlpRegression(X_train,X_test,y_train,y_test, mlp_params)\n",
    "\n",
    "  def wine_quality(self):\n",
    "    df = pd.read_csv('winequality-red.csv',delimiter=';')\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    #print(df.corr()['quality'].drop('quality'))\n",
    "    X = df[df.columns[0:11]]\n",
    "    y = df[df.columns[11:12]]\n",
    "    self.train_all__models(X, y.values.ravel())\n",
    "\n",
    "  def communities(self):\n",
    "    columns_data = ['state','county','community','communityname','fold','population','householdsize','racepctblack','racePctWhite','racePctAsian','racePctHisp','agePct12t21',\n",
    "                    'agePct12t29','agePct16t24','agePct65up','numbUrban','pctUrban','medIncome','pctWWage','pctWFarmSelf','pctWInvInc','pctWSocSec','pctWPubAsst','pctWRetire','medFamInc',\n",
    "                    'perCapInc','whitePerCap','blackPerCap','indianPerCap','AsianPerCap','OtherPerCap','HispPerCap','NumUnderPov','PctPopUnderPov','PctLess9thGrade',\n",
    "                    'PctNotHSGrad','PctBSorMore','PctUnemployed','PctEmploy','PctEmplManu','PctEmplProfServ','PctOccupManu','PctOccupMgmtProf','MalePctDivorce','MalePctNevMarr',\n",
    "                    'FemalePctDiv','TotalPctDiv','PersPerFam','PctFam2Par','PctKids2Par','PctYoungKids2Par','PctTeen2Par','PctWorkMomYoungKids','PctWorkMom','NumIlleg','PctIlleg',\n",
    "                    'NumImmig','PctImmigRecent','PctImmigRec5','PctImmigRec8','PctImmigRec10','PctRecentImmig','PctRecImmig5','PctRecImmig8','PctRecImmig10','PctSpeakEnglOnly','PctNotSpeakEnglWell'\n",
    "                    ,'PctLargHouseFam','PctLargHouseOccup','PersPerOccupHous','PersPerOwnOccHous','PersPerRentOccHous','PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR',\n",
    "                    'MedNumBR','HousVacant','PctHousOccup','PctHousOwnOcc','PctVacantBoarded','PctVacMore6Mos','MedYrHousBuilt','PctHousNoPhone','PctWOFullPlumb','OwnOccLowQuart','OwnOccMedVal',\n",
    "                    'OwnOccHiQuart','RentLowQ','RentMedian','RentHighQ','MedRent','MedRentPctHousInc','MedOwnCostPctInc','MedOwnCostPctIncNoMtg','NumInShelters','NumStreet','PctForeignBorn',\n",
    "                    'PctBornSameState','PctSameHouse85','PctSameCity85','PctSameState85','LemasSwornFT','LemasSwFTPerPop','LemasSwFTFieldOps','LemasSwFTFieldPerPop','LemasTotalReq','LemasTotReqPerPop',\n",
    "                    'PolicReqPerOffic','PolicPerPop','RacialMatchCommPol','PctPolicWhite','PctPolicBlack','PctPolicHisp','PctPolicAsian','PctPolicMinor','OfficAssgnDrugUnits','NumKindsDrugsSeiz',\n",
    "                    'PolicAveOTWorked','LandArea','PopDens','PctUsePubTrans','PolicCars','PolicOperBudg','LemasPctPolicOnPatr','LemasGangUnitDeploy','LemasPctOfficDrugUn','PolicBudgPerPop',\n",
    "                    'ViolentCrimesPerPop'\n",
    "                    ]\n",
    "    df = pd.read_csv('communities.data',delimiter=',',names=columns_data)\n",
    "\n",
    "    #print(\"Before Removing the Non Predictable Features \\n\")\n",
    "    #print(\"Shape Before Removing :\" +str(df.shape) + \"\\n\")\n",
    "    #print(df.head())\n",
    "    df = df.replace('?',np.nan)\n",
    "    #print(\"After Removing the Non predictable Features \\n \")\n",
    "    #print(\"Shape After Removing :\" + str(df.shape) + \"\\n\")\n",
    "    #print(df.head())\n",
    "    print(\"Before Droping data Shape \" + str(df.shape))\n",
    "    #According to Dataset Description there are 5 non predictive features which can be removed\n",
    "    df = df.drop(['fold','community','state','communityname','county'],axis=1)\n",
    "\n",
    "    print(\"Checking the Columns Containing the null Values\")\n",
    "    \n",
    "    #for i in range(0,120,41):\n",
    "    #  print(df.iloc[:,i:i+41].isna().sum())\n",
    "    #  print(\"\\n\")\n",
    "    median_value = df.iloc[:,25].median(skipna = True)\n",
    "    df.iloc[130,25] = median_value\n",
    "    \n",
    "    df = df.dropna(axis=1)\n",
    "    print(df.columns)\n",
    "    print(\"After Droping data Shape \" + str(df.shape))\n",
    "    #Replacing the columns with median\n",
    "  \n",
    "\n",
    "    print(\"Number of Missing Values in column is \" + str(df.iloc[:,25].isna().sum()))\n",
    "    print(df.shape)\n",
    "    X = df[df.columns[0:100]]\n",
    "    y = df[df.columns[100:101]]\n",
    "    print(X.describe())\n",
    "    #print(y)\n",
    "    #print(X.head())\n",
    "    self.train_all__models(X, y.values.ravel())\n",
    "    \n",
    "     def speech_data(self):\n",
    "        col = ['Subject_id','local_jitter','absolute_jitter','rap_jitter','ppq5_jitter','ddp_jitter','local_shimmer',\n",
    "                       'db_shimmer','apq3_shimmer','apq5_shimmer','apq11_shimmer','dda_shimmer','AC','NTH','HTN','Median_pitch',\n",
    "                       'Mean_pitch','Standard_deviation','Minimum_pitch','Maximum_pitch','Number_of_pulses','Number_of_periods',\n",
    "                       'Mean_period','Standard_deviation_of_period','Fraction_of_locally_unvoiced_frames','Number_of_voice_breaks',\n",
    "                       'Degree_of_voice_breaks','UPDRS','class_info']\n",
    "        data = pd.read_csv(\"../Datasets/Parkinson_Multiple_Sound_Recording/Prakinson_Multiple_sound_recording_train_data.txt\")\n",
    "        data.columns=col\n",
    "\n",
    "        data.columns = data.columns.str.lstrip()\n",
    "        a = StandardScaler()\n",
    "        X = data.drop(['class_info'],axis=1)\n",
    "        X = a.fit_transform(X)\n",
    "        y = data['class_info']\n",
    "        self.train_all__models(X, y.values.ravel())\n",
    "    \n",
    "    def concrete_data(self):\n",
    "        col = ['Cement','Blast Furnace Slag','Fly Ash','Water','Superplasticizer','Coarse Aggregate','Fine Aggregate',\n",
    "                       'Age','Concrete compressive strength']\n",
    "        data  = pd.read_excel(\"../Datasets/concrete_data/Concrete_compressive_strength_Data.xls\",skiprows=1)\n",
    "        data.columns=col\n",
    "\n",
    "        data.columns = data.columns.str.lstrip()\n",
    "        a = StandardScaler()\n",
    "        X = data.drop(['Concrete compressive strength'],axis=1)\n",
    "        X = a.fit_transform(X)\n",
    "        y = data['Concrete compressive strength']\n",
    "        self.train_all__models(X, y.values.ravel())\n",
    "        \n",
    "    \n",
    "    def student_data_train_G3(self):\n",
    "        df1 = pd.read_csv(\"../Datasets/Student_performance/student1/student-mat.csv\",delimiter=\";\")\n",
    "        df2 = pd.read_csv(\"../Datasets/Student_performance/student1/student-por.csv\",delimiter=\";\")\n",
    "\n",
    "        data = pd.concat([df1,df2])\n",
    "\n",
    "        categorical_columns = ['school','sex','famsize','address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup',\n",
    "                               'famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "        for i in categorical_columns:\n",
    "            data[i] = pd.Categorical(data[i]).codes\n",
    "\n",
    "        data.columns = data.columns.str.lstrip()\n",
    "        a = StandardScaler()\n",
    "       \n",
    "        X = a.fit_transform(data)\n",
    "        y = data['G3']\n",
    "        self.train_all__models(X, y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zaAUEUKEB5ZP",
    "outputId": "1351aa47-9942-4de8-92a3-1f46d51fd12e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegressionModels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e7aed209c37c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregressionModels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegressionModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mregressionModels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwine_quality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mregressionModels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mregressionModels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcrete_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mregressionModels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudent_data_train_G3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RegressionModels' is not defined"
     ]
    }
   ],
   "source": [
    "regressionModels = RegressionModels()\n",
    "regressionModels.wine_quality()\n",
    "regressionModels.speech_data()\n",
    "regressionModels.concrete_data()\n",
    "regressionModels.student_data_train_G3()\n",
    "#regressionModels.communities()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "General_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
