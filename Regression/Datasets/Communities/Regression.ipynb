{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pqGoSsuAAgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "#%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkJiN_c1Bfqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RegressionModels():\n",
        "\n",
        "  def preprocessing(self):\n",
        "    kfolds = KFold(n_splits=5,shuffle=True)\n",
        "    return kfolds\n",
        "\n",
        "  def modelTraining(self,clf,X,y,kfolds):\n",
        "    avg_score = []\n",
        "    varance_score = []\n",
        "    r2Score = []\n",
        "    for train, test in kfolds.split(X):\n",
        "      X_train, X_test = X.iloc[train], X.iloc[test]\n",
        "      y_train, y_test = y[train], y[test]\n",
        "      clf.fit(X_train,y_train)\n",
        "      y_pred = clf.predict(X_test)\n",
        "      mse = mean_squared_error(y_test, y_pred)\n",
        "      score = clf.score(X_test,y_test)\n",
        "      temp_variance_score = explained_variance_score(y_test, y_pred)\n",
        "      varance_score.append(temp_variance_score)\n",
        "      #print(\"Score \" , score)\n",
        "      r2Score.append(r2_score(y_test,y_pred))\n",
        "      avg_score.append(math.sqrt(mse))\n",
        "    print(\"Mean variance Score \" ,np.mean(varance_score))\n",
        "    print(\"Mean R2 Score \", np.mean(r2Score))\n",
        "    return np.mean(avg_score)\n",
        "\n",
        "  def svmRegression(self, kfolds, X, y, params):\n",
        "    clf = SVR(gamma='scale', C=2.0, epsilon=0.3)\n",
        "    mean_accuracy = self.modelTraining(clf,X,y,kfolds)\n",
        "    print(\"SVM Regression Mean Accuracy \",mean_accuracy)\n",
        "\n",
        "  def decisionTreeRegression(self, kfolds, X, y, params):\n",
        "    DTregressor = DecisionTreeRegressor(random_state=0)\n",
        "    #scores = cross_val_score(DTregressor, X_train, y_train, cv=5)\n",
        "    mean_accuracy = self.modelTraining(DTregressor,X,y,kfolds)\n",
        "    print(\"Mean accruacy for Decision Tree :\", mean_accuracy)\n",
        "\n",
        "  def randomForestRegression(self, kfolds, X, y, params):\n",
        "    RDRegressor = RandomForestRegressor(max_depth=2, random_state=0,n_estimators=100)\n",
        "    mean_accuracy = self.modelTraining(RDRegressor, X, y, params)\n",
        "    print(RDRegressor.feature_importances_)\n",
        "    print(\"Mean accuracy for Random Forest :\" , mean_accuracy)\n",
        "  \n",
        "  def adaBoostRegression(self, kfolds, X, y, params):\n",
        "    AdaRegressor = AdaBoostRegressor(random_state=0,n_estimators=100)\n",
        "    mean_accuracy = self.modelTraining(AdaRegressor, X, y, params)\n",
        "    print(AdaRegressor.feature_importances_)\n",
        "    print(\"Score value : \", AdaRegressor.score(X, y))\n",
        "    print(\"Mean accuracy for Random Forest :\" , mean_accuracy)\n",
        "\n",
        "  def gaussianProcessRegression(self, kfolds, X, y, params):\n",
        "    kernelP = DotProduct() + WhiteKernel()\n",
        "    GPRRegressor = GaussianProcessRegressor(kernel=kernelP, random_state=0,n_estimators=100)\n",
        "    mean_accuracy = self.modelTraining(GPRRegressor, X, y, params)\n",
        "    print(GPRRegressor.score(X, y))\n",
        "    print(\"Mean accuracy for Random Forest :\" , mean_accuracy)\n",
        "\n",
        "  def LinearRegression(self, kfolds, X, y, params):\n",
        "    LinearRegressor = LinearRegression()\n",
        "    mean_accuracy = self.modelTraining(LinearRegressor, X, y, params)\n",
        "    print(LinearRegressor.score(X, y))\n",
        "    print(\"Mean accuracy for Random Forest :\" , mean_accuracy)\n",
        "\n",
        "  def mlpRegression(self, kfolds, X, y, params):\n",
        "    MLPRegressor = MLPRegressor(hidden_layer_sizes =(50,100), activation='relu',random_state=0)\n",
        "    mean_accuracy = self.modelTraining(MLPRegressor, X, y, params)\n",
        "    print(MLPRegressor.feature_importances_)\n",
        "    print(\"Mean accuracy for Random Forest :\" , mean_accuracy)\n",
        "\n",
        "  def train_all__models(self, kfolds, X, y):\n",
        "    svm_regression_params = {}\n",
        "    dt_params = {}\n",
        "    rd_params = {}\n",
        "    self.svmRegression(kfolds, X, y, svm_regression_params)\n",
        "    self.decisionTreeRegression(kfolds, X, y, dt_params)\n",
        "    self.randomForestRegression(kfolds, X, y, rd_params)\n",
        "    self.adaBoostRegression(kfolds, X, y, rd_params)\n",
        "    self.gaussianProcessRegression(kfolds, X, y, rd_params)\n",
        "    self.LinearRegression(kfolds, X, y, rd_params)\n",
        "    self.mlpRegression(kfolds, X, y, rd_params)\n",
        "\n",
        "  def wine_quality(self):\n",
        "    df = pd.read_csv('winequality-red.csv',delimiter=';')\n",
        "    df.dropna(axis=0,inplace=True)\n",
        "    print(df.corr()['quality'].drop('quality'))\n",
        "    X = df[df.columns[0:11]]\n",
        "    y = df[df.columns[11:12]]\n",
        "    kfolds = self.preprocessing()\n",
        "    self.train_all__models(kfolds, X, y.values.ravel())\n",
        "\n",
        "  def communities(self):\n",
        "    columns_data = ['state','county','community','communityname','fold','population','householdsize','racepctblack','racePctWhite','racePctAsian','racePctHisp','agePct12t21',\n",
        "                    'agePct12t29','agePct16t24','agePct65up','numbUrban','pctUrban','medIncome','pctWWage','pctWFarmSelf','pctWInvInc','pctWSocSec','pctWPubAsst','pctWRetire','medFamInc',\n",
        "                    'perCapInc','whitePerCap','blackPerCap','indianPerCap','AsianPerCap','OtherPerCap','HispPerCap','NumUnderPov','PctPopUnderPov','PctLess9thGrade',\n",
        "                    'PctNotHSGrad','PctBSorMore','PctUnemployed','PctEmploy','PctEmplManu','PctEmplProfServ','PctOccupManu','PctOccupMgmtProf','MalePctDivorce','MalePctNevMarr',\n",
        "                    'FemalePctDiv','TotalPctDiv','PersPerFam','PctFam2Par','PctKids2Par','PctYoungKids2Par','PctTeen2Par','PctWorkMomYoungKids','PctWorkMom','NumIlleg','PctIlleg',\n",
        "                    'NumImmig','PctImmigRecent','PctImmigRec5','PctImmigRec8','PctImmigRec10','PctRecentImmig','PctRecImmig5','PctRecImmig8','PctRecImmig10','PctSpeakEnglOnly','PctNotSpeakEnglWell'\n",
        "                    ,'PctLargHouseFam','PctLargHouseOccup','PersPerOccupHous','PersPerOwnOccHous','PersPerRentOccHous','PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR',\n",
        "                    'MedNumBR','HousVacant','PctHousOccup','PctHousOwnOcc','PctVacantBoarded','PctVacMore6Mos','MedYrHousBuilt','PctHousNoPhone','PctWOFullPlumb','OwnOccLowQuart','OwnOccMedVal',\n",
        "                    'OwnOccHiQuart','RentLowQ','RentMedian','RentHighQ','MedRent','MedRentPctHousInc','MedOwnCostPctInc','MedOwnCostPctIncNoMtg','NumInShelters','NumStreet','PctForeignBorn',\n",
        "                    'PctBornSameState','PctSameHouse85','PctSameCity85','PctSameState85','LemasSwornFT','LemasSwFTPerPop','LemasSwFTFieldOps','LemasSwFTFieldPerPop','LemasTotalReq','LemasTotReqPerPop',\n",
        "                    'PolicReqPerOffic','PolicPerPop','RacialMatchCommPol','PctPolicWhite','PctPolicBlack','PctPolicHisp','PctPolicAsian','PctPolicMinor','OfficAssgnDrugUnits','NumKindsDrugsSeiz',\n",
        "                    'PolicAveOTWorked','LandArea','PopDens','PctUsePubTrans','PolicCars','PolicOperBudg','LemasPctPolicOnPatr','LemasGangUnitDeploy','LemasPctOfficDrugUn','PolicBudgPerPop',\n",
        "                    'ViolentCrimesPerPop'\n",
        "                    ]\n",
        "    df = pd.read_csv('communities.data',delimiter=',',names=columns_data)\n",
        "\n",
        "    #print(\"Before Removing the Non Predictable Features \\n\")\n",
        "    #print(\"Shape Before Removing :\" +str(df.shape) + \"\\n\")\n",
        "    #print(df.head())\n",
        "    df = df.replace('?',np.nan)\n",
        "    #print(\"After Removing the Non predictable Features \\n \")\n",
        "    #print(\"Shape After Removing :\" + str(df.shape) + \"\\n\")\n",
        "    #print(df.head())\n",
        "    print(\"Before Droping data Shape \" + str(df.shape))\n",
        "    #According to Dataset Description there are 5 non predictive features which can be removed\n",
        "    df = df.drop(['fold','community','state','communityname','county'],axis=1)\n",
        "\n",
        "    print(\"Checking the Columns Containing the null Values\")\n",
        "    \n",
        "    #for i in range(0,120,41):\n",
        "    #  print(df.iloc[:,i:i+41].isna().sum())\n",
        "    #  print(\"\\n\")\n",
        "    median_value = df.iloc[:,25].median(skipna = True)\n",
        "    df.iloc[130,25] = median_value\n",
        "    \n",
        "    df = df.dropna(axis=1)\n",
        "    print(df.columns)\n",
        "    print(\"After Droping data Shape \" + str(df.shape))\n",
        "    #Replacing the columns with median\n",
        "  \n",
        "\n",
        "    print(\"Number of Missing Values in column is \" + str(df.iloc[:,25].isna().sum()))\n",
        "    print(df.shape)\n",
        "    X = df[df.columns[0:100]]\n",
        "    y = df[df.columns[100:101]]\n",
        "    print(X.describe())\n",
        "    #print(y)\n",
        "    kfolds = self.preprocessing()\n",
        "    #print(X.head())\n",
        "    self.train_all__models(kfolds, X, y.values.ravel())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAUEUKEB5ZP",
        "colab_type": "code",
        "outputId": "bd3a6e62-5731-4f72-f2cc-a8e182d0af71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "regressionModels = RegressionModels()\n",
        "#regressionModels.wine_quality()\n",
        "regressionModels.communities()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Droping data Shape (1994, 128)\n",
            "Checking the Columns Containing the null Values\n",
            "Index(['population', 'householdsize', 'racepctblack', 'racePctWhite',\n",
            "       'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29',\n",
            "       'agePct16t24', 'agePct65up',\n",
            "       ...\n",
            "       'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85',\n",
            "       'PctSameState85', 'LandArea', 'PopDens', 'PctUsePubTrans',\n",
            "       'LemasPctOfficDrugUn', 'ViolentCrimesPerPop'],\n",
            "      dtype='object', length=101)\n",
            "After Droping data Shape (1994, 101)\n",
            "Number of Missing Values in column is 0\n",
            "(1994, 101)\n",
            "        population  householdsize  ...  PctUsePubTrans  LemasPctOfficDrugUn\n",
            "count  1994.000000    1994.000000  ...     1994.000000          1994.000000\n",
            "mean      0.057593       0.463395  ...        0.161685             0.094052\n",
            "std       0.126906       0.163717  ...        0.229055             0.240328\n",
            "min       0.000000       0.000000  ...        0.000000             0.000000\n",
            "25%       0.010000       0.350000  ...        0.020000             0.000000\n",
            "50%       0.020000       0.440000  ...        0.070000             0.000000\n",
            "75%       0.050000       0.540000  ...        0.190000             0.000000\n",
            "max       1.000000       1.000000  ...        1.000000             1.000000\n",
            "\n",
            "[8 rows x 99 columns]\n",
            "Variance Score  0.5227001716439577\n",
            "Variance Score  0.517556898859378\n",
            "Variance Score  0.5289239067014307\n",
            "Variance Score  0.5593958200736192\n",
            "Variance Score  0.5536683502800746\n",
            "SVM Regression Mean Accuracy  0.21241574778938635\n",
            "Variance Score  0.17717000500749414\n",
            "Variance Score  0.2960844795510471\n",
            "Variance Score  0.4189892672147756\n",
            "Variance Score  0.2675496364510429\n",
            "Variance Score  0.14656508946422042\n",
            "Mean accruacy for Decision Tree : 0.1989472232326779\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}